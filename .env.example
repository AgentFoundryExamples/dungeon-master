# Dungeon Master Service Configuration
# Copy this file to .env and fill in your actual values

# ============================================================================
# JOURNEY-LOG SERVICE CONFIGURATION
# ============================================================================

# Base URL for the journey-log service (required)
# Examples: http://localhost:8000, https://journey-log-abcd123-uc.a.run.app
JOURNEY_LOG_BASE_URL=http://localhost:8000

# HTTP timeout for journey-log requests in seconds (default: 30)
# Range: 1-300 seconds
JOURNEY_LOG_TIMEOUT=30


# ============================================================================
# OPENAI API CONFIGURATION
# ============================================================================

# OpenAI API key for LLM requests (required)
# Get your key from: https://platform.openai.com/api-keys
# IMPORTANT: Never commit this value to source control
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI model to use for narrative generation (default: gpt-5.1)
# For GPT-5+ models, use gpt-5.1 or later (see infrastructure_versions.txt)
# Examples: gpt-4, gpt-5.1, gpt-4-turbo-preview
OPENAI_MODEL=gpt-5.1

# HTTP timeout for OpenAI requests in seconds (default: 60)
# Range: 1-600 seconds
# Note: LLM generation can take time, set appropriately
OPENAI_TIMEOUT=60

# Enable stub mode for offline development (default: false)
# When true, LLM client returns stub responses without calling OpenAI API
# Useful for testing and development without API costs
OPENAI_STUB_MODE=false


# ============================================================================
# JOURNEY-LOG CLIENT CONFIGURATION
# ============================================================================

# Default number of recent narrative turns to fetch (default: 20)
# Range: 1-100
# This controls how much recent history is sent to the LLM for context
JOURNEY_LOG_RECENT_N=20


# ============================================================================
# HEALTH CHECK CONFIGURATION
# ============================================================================

# Whether to ping journey-log service during health checks (default: false)
# Set to true to enable health endpoint to check journey-log accessibility
# Note: Health checks use a short 5-second timeout
HEALTH_CHECK_JOURNEY_LOG=false


# ============================================================================
# SERVICE CONFIGURATION
# ============================================================================

# Service name for logging and identification (default: dungeon-master)
SERVICE_NAME=dungeon-master

# Logging level (default: INFO)
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable JSON structured logging output (default: false)
# Set to true for easier parsing by log aggregation tools (e.g., CloudWatch)
LOG_JSON_FORMAT=false

# ============================================================================
# CHARACTER STATUS AND GAME OVER RULES
# ============================================================================
# The service enforces strict character status transitions:
#   Healthy -> Wounded -> Dead
#
# Healing Rules:
# - Characters can be healed from Wounded back to Healthy
# - Characters CANNOT be revived from Dead status (death is final)
#
# Game Over Logic:
# - When a character reaches Dead status, the session is OVER
# - LLM generates a final narrative and sets all intents to "none"
# - Clients should detect Dead status and prevent further turn submissions
#
# No configuration variables required - rules are embedded in system prompt
# See app/prompting/prompt_builder.py for implementation details


# ============================================================================
# METRICS CONFIGURATION
# ============================================================================

# Enable metrics collection and /metrics endpoint (default: false)
# When enabled, service collects metrics on requests, errors, and latencies
ENABLE_METRICS=false


# ============================================================================
# DEBUG CONFIGURATION
# ============================================================================

# Enable debug endpoints like /debug/parse_llm (default: false)
# WARNING: Only enable for local development. Do NOT enable in production.
# Debug endpoints expose internal parsing logic and should be protected.
ENABLE_DEBUG_ENDPOINTS=false


# ============================================================================
# POLICY ENGINE CONFIGURATION
# ============================================================================

# Quest trigger probability (default: 0.3)
# Range: 0.0-1.0
# Controls the likelihood of quest triggers per turn
QUEST_TRIGGER_PROB=0.3

# Quest cooldown turns (default: 5)
# Minimum: 0 (zero or negative values skip waiting periods)
# Number of turns that must pass between quest triggers
QUEST_COOLDOWN_TURNS=5

# POI trigger probability (default: 0.2)
# Range: 0.0-1.0
# Controls the likelihood of POI (Point of Interest) triggers per turn
POI_TRIGGER_PROB=0.2

# POI cooldown turns (default: 3)
# Minimum: 0 (zero or negative values skip waiting periods)
# Number of turns that must pass between POI triggers
POI_COOLDOWN_TURNS=3

# Enable POI memory sparks (default: false)
# When enabled, fetches random POIs to inject as memory sparks in prompts
# This helps the LLM recall and reference previously discovered locations
POI_MEMORY_SPARK_ENABLED=false

# Number of random POIs to fetch as memory sparks (default: 3)
# Range: 1-20
# Only used when POI_MEMORY_SPARK_ENABLED is true
POI_MEMORY_SPARK_COUNT=3


# ============================================================================
# ADMIN AND POLICY CONFIGURATION
# ============================================================================

# Optional path to JSON file for runtime policy config (probabilities, cooldowns)
# If not set, policy parameters from environment variables are used
# See policy_config.json.example for file format
# POLICY_CONFIG_FILE=/path/to/policy_config.json

# Enable admin endpoints for turn introspection and policy management (default: false)
# When enabled, provides:
# - GET /admin/turns/{turn_id} - Inspect specific turn details
# - GET /admin/characters/{id}/recent_turns - List recent turns for a character
# - GET /admin/policy/config - View current policy configuration
# - POST /admin/policy/reload - Reload policy config from file or provided values
# WARNING: Admin endpoints rely on Cloud IAM/service-to-service auth.
#          Do not expose publicly without proper authentication.
ADMIN_ENDPOINTS_ENABLED=false

# TTL for turn details in storage (default: 3600, range: 60-86400 seconds)
# Turns older than this will be expired and removed from storage
# Default: 1 hour (3600 seconds)
TURN_STORAGE_TTL_SECONDS=3600

# Maximum number of turns to store in memory (default: 10000, range: 100-100000)
# When this limit is reached, oldest turns are evicted (LRU)
# Default: 10000 turns
TURN_STORAGE_MAX_SIZE=10000

# RNG seed for deterministic debugging (default: unset)
# When unset, uses secure randomness (recommended for production)
# When set to an integer, enables reproducible random behavior for testing
# This is useful for:
# - Debugging policy decision logic
# - Writing deterministic integration tests
# - Reproducing specific gameplay scenarios
# Example: RNG_SEED=12345
# Note: Each character gets their own RNG sequence derived from this seed
# RNG_SEED=


# ============================================================================
# POLICY ENGINE DEBUG PROFILES
# ============================================================================

# The policy engine supports various profiles for different testing scenarios.
# Uncomment one of the profiles below to test specific behaviors:

# --- High Frequency Profile ---
# For testing frequent quest and POI triggers
# QUEST_TRIGGER_PROB=0.9
# QUEST_COOLDOWN_TURNS=1
# POI_TRIGGER_PROB=0.8
# POI_COOLDOWN_TURNS=1
# RNG_SEED=42

# --- Low Frequency Profile ---
# For testing rare triggers and long cooldowns
# QUEST_TRIGGER_PROB=0.1
# QUEST_COOLDOWN_TURNS=10
# POI_TRIGGER_PROB=0.1
# POI_COOLDOWN_TURNS=10
# RNG_SEED=42

# --- Deterministic Testing Profile ---
# For testing with predictable outcomes
# QUEST_TRIGGER_PROB=1.0
# QUEST_COOLDOWN_TURNS=0
# POI_TRIGGER_PROB=1.0
# POI_COOLDOWN_TURNS=0
# RNG_SEED=999

# --- Disabled Profile ---
# For testing with triggers completely disabled
# QUEST_TRIGGER_PROB=0.0
# QUEST_COOLDOWN_TURNS=999
# POI_TRIGGER_PROB=0.0
# POI_COOLDOWN_TURNS=999
# RNG_SEED=0


# ============================================================================
# RATE LIMITING CONFIGURATION
# ============================================================================

# Maximum turns per character per second (default: 2.0)
# Range: 0.1-100.0
# Conservative default to prevent runaway resource usage per character
MAX_TURNS_PER_CHARACTER_PER_SECOND=2.0

# Maximum concurrent LLM calls across all characters (default: 10)
# Range: 1-100
# Prevents API rate limit exhaustion and controls resource usage
MAX_CONCURRENT_LLM_CALLS=10


# ============================================================================
# RETRY AND BACKOFF CONFIGURATION
# ============================================================================

# Maximum retry attempts for transient LLM errors (default: 3)
# Range: 0-10
# Set to 0 to disable retries. Applies to timeouts and rate limit errors.
LLM_MAX_RETRIES=3

# Base delay for LLM retry exponential backoff in seconds (default: 1.0)
# Range: 0.1-10.0
# First retry after base_delay, second after base_delay * 2, etc.
LLM_RETRY_DELAY_BASE=1.0

# Maximum delay for LLM retry exponential backoff in seconds (default: 30.0)
# Range: 1.0-300.0
# Caps the exponential backoff to prevent excessively long waits
LLM_RETRY_DELAY_MAX=30.0

# Maximum retry attempts for journey-log GET requests (default: 3)
# Range: 0-10
# Note: POST/PUT/DELETE operations are never retried to prevent duplicates
JOURNEY_LOG_MAX_RETRIES=3

# Base delay for journey-log retry exponential backoff in seconds (default: 0.5)
# Range: 0.1-10.0
JOURNEY_LOG_RETRY_DELAY_BASE=0.5

# Maximum delay for journey-log retry exponential backoff in seconds (default: 10.0)
# Range: 1.0-300.0
JOURNEY_LOG_RETRY_DELAY_MAX=10.0


# ============================================================================
# GOOGLE CLOUD PLATFORM (GCP) DEPLOYMENT CONFIGURATION
# ============================================================================

# GCP Project ID where the service will be deployed (optional for local dev)
# Required for: Cloud Run deployments, Secret Manager access, Artifact Registry
# Format: lowercase letters, digits, and hyphens (e.g., my-project-123)
# Leave empty for local development. Must be set for production deployments.
# See: gcp_deployment_reference.md for deployment architecture details
# GCP_PROJECT_ID=

# GCP Region for Cloud Run deployment (default: us-central1)
# Common regions: us-central1, us-east1, us-west1, europe-west1, asia-northeast1
# Choose based on: latency requirements, compliance, cost
# See: https://cloud.google.com/run/docs/locations
GCP_REGION=us-central1

# Cloud Run service name (default: dungeon-master)
# Must match [a-z0-9-]+ pattern, max 63 characters
# Used for: service identification, metrics labeling, logging
# For multi-environment: use suffixes like dungeon-master-dev, dungeon-master-prod
CLOUD_RUN_SERVICE=dungeon-master

# Artifact Registry repository name (default: dungeon-master)
# Format: lowercase letters, digits, and hyphens
# Full image path: REGION-docker.pkg.dev/PROJECT_ID/REPO/IMAGE:TAG
# Example: us-central1-docker.pkg.dev/my-project/dungeon-master/app:v1.0.0
# Repository must be created before deployment (see gcp_deployment_reference.md)
ARTIFACT_REPO=dungeon-master

# Secret Manager configuration mode (default: disabled)
# Options:
#   - disabled: Use environment variables only (local dev, simple deployments)
#   - env_vars: Mount secrets as environment variables in Cloud Run
#   - volume: Mount secrets as files in Cloud Run (more secure for certificates/keys)
# When enabled, OPENAI_API_KEY and other secrets should be stored in Secret Manager
# See: gcp_deployment_reference.md for Secret Manager setup instructions
SECRET_MANAGER_CONFIG=disabled
